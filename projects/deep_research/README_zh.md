# Agentic Insight

### è½»é‡ã€é«˜æ•ˆã€å¯æ‰©å±•çš„å¤šæ¨¡æ€æ·±åº¦ç ”ç©¶æ¡†æ¶

&nbsp;
&nbsp;

æœ¬é¡¹ç›®æä¾›ä¸€ä¸ªç”¨äºæ·±åº¦ç ”ç©¶ï¼ˆdeep researchï¼‰ä»»åŠ¡çš„æ¡†æ¶ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªä¸»æ¢ç´¢å¹¶æ‰§è¡Œå¤æ‚ä»»åŠ¡ã€‚

### ğŸŒŸ åŠŸèƒ½ç‰¹æ€§

- **è‡ªä¸»æ¢ç´¢ï¼ˆAutonomous Explorationï¼‰** - é¢å‘å„ç±»å¤æ‚ä»»åŠ¡çš„è‡ªä¸»æ¢ç´¢èƒ½åŠ›

- **å¤šæ¨¡æ€ï¼ˆMultimodalï¼‰** - èƒ½å¤„ç†å¤šç§æ•°æ®æ¨¡æ€ï¼Œå¹¶ç”ŸæˆåŒ…å«æ–‡æœ¬ä¸å›¾ç‰‡çš„ç ”ç©¶æŠ¥å‘Šã€‚

- **è½»é‡ä¸é«˜æ•ˆï¼ˆLightweight & Efficientï¼‰** - æ”¯æŒ â€œsearch-then-executeâ€ æ¨¡å¼ï¼Œå¯åœ¨æ•°åˆ†é’Ÿå†…å®Œæˆå¤æ‚ç ”ç©¶ä»»åŠ¡ï¼Œæ˜¾è‘—é™ä½ token æ¶ˆè€—ã€‚

- **å¯æ‰©å±•æ·±åº¦æœç´¢æ¶æ„ï¼ˆExpandable Deep Search Architectureï¼‰** â€” å¯ä»è½»é‡æ£€ç´¢æ‰©å±•ä¸ºé€’å½’å¼æ·±åº¦æ£€ç´¢ï¼šè‡ªåŠ¨ç”Ÿæˆè¿½é—®ï¼›å¯é…ç½® breadth/depth å‚æ•°æ§åˆ¶æœç´¢é¢„ç®—ï¼›é€šè¿‡ç¨ å¯†çš„æ€»ç»“ä¿¡æ¯åšæ¸…æ™°çš„ä¸Šä¸‹æ–‡äº¤æ¥ï¼›æ”¯æŒä½¿ç”¨ docling è¿›è¡Œå¤šæ¨¡æ€é›†æˆå¹¶å°½é‡ä¿ç•™å›¾è¡¨æ ‡é¢˜ä¸é¡ºåºã€‚

### ğŸ†• Agentic Insight v2ï¼ˆæ¨èï¼‰

æœ¬ç›®å½•åŒæ—¶åŒ…å«æ—§ç‰ˆå®ç°ï¼ˆä¸‹æ–¹çš„ Python API ç¤ºä¾‹ï¼‰ä»¥åŠæ›´æ–°çš„ **Agentic Insight v2**ã€‚v2 é‡ç‚¹å¼ºè°ƒï¼š

- **å¯æ‰©å±•çš„ä¸» agent + å­ agent æ¶æ„**ï¼šResearcher è´Ÿè´£ç¼–æ’ Searcher/Reporterï¼Œå¹¶å¯æ‰©å±•æ–°çš„å­ agent ä¸å·¥å…·ã€‚

- **åŸºäºæ–‡ä»¶ç³»ç»Ÿçš„ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šé€šè¿‡åœ¨ç£ç›˜ä¸Šå­˜å‚¨ç»“æ„åŒ–ä¸­é—´äº§ç‰©æ¥ç®¡ç†ä¸Šä¸‹æ–‡ï¼Œæ›´åŠ çµæ´»ã€æ˜“è°ƒè¯•ï¼Œä¸”æ”¯æŒæ–­ç‚¹ç»­è·‘ã€‚

- **é¢å‘ deep research ä¼˜åŒ–çš„å·¥å…·é“¾**ï¼šå›´ç»•è¿­ä»£å¼ç ”ç©¶å¾ªç¯æä¾›ä¸“ç”¨çš„ todoã€evidenceã€searchã€report å·¥å…·ã€‚

- **åŸºäºè¯æ®ç»‘å®šçš„æŠ¥å‘Šç”Ÿæˆ**ï¼šæŠ¥å‘Šä»åŸå§‹è¯æ®å‡ºå‘å¹¶è¿›è¡Œæ˜¾å¼è¯æ®ç»‘å®šï¼Œä»è€Œæå‡å¯ä¿¡åº¦ä¸å¯è¿½æº¯æ€§ã€‚

v2 çš„ä½¿ç”¨æ–¹å¼ä¸è¯¦ç»†è¯´æ˜è§ï¼š

- è‹±æ–‡ï¼š [Agentic Insight v2 Guide](v2/README.md)
- ä¸­æ–‡ï¼š [Agentic Insight v2 ä½¿ç”¨è¯´æ˜](v2/README_zh.md)

### ğŸ“º æ¼”ç¤º

ä¸‹é¢å±•ç¤º Agentic Insight æ¡†æ¶çš„ä¸€ä¸ªæ¼”ç¤ºæ¡ˆä¾‹ï¼Œç”¨äºä½“ç°å…¶åœ¨é«˜æ•ˆå¤„ç†å¤æ‚ç ”ç©¶ä»»åŠ¡æ–¹é¢çš„èƒ½åŠ›ã€‚

#### ç”¨æˆ·é—®é¢˜

* ä¸­æ–‡:
```text
åœ¨è®¡ç®—åŒ–å­¦è¿™ä¸ªé¢†åŸŸï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨Gaussianè½¯ä»¶æ¨¡æ‹Ÿå„ç§æƒ…å†µä¸‹åˆ†å­çš„ç»“æ„å’Œæ€§è´¨è®¡ç®—ï¼Œæ¯”å¦‚åœ¨å…³é”®è¯ä¸­åŠ å…¥'field=x+100'ä»£è¡¨äº†åœ¨xæ–¹å‘å¢åŠ äº†ç”µåœºã€‚ä½†æ˜¯ï¼Œå½“ä½“ç³»æ˜¯ç»å…¸çš„å•åŸå­å‚¬åŒ–å‰‚æ—¶ï¼Œå®ƒå±äºåˆ†å­å‚¬åŒ–å‰‚ï¼Œåœ¨ååº”ç¯å¢ƒä¸­åˆ†å­çš„æœå‘æ˜¯ä¸ç¡®å®šçš„ï¼Œé‚£ä¹ˆç†è®ºæ¨¡æ‹Ÿçš„xæ–¹å‘ç”µåœºå’Œå®é™…ç”µåœºæ˜¯ä¸ä¸€è‡´çš„ã€‚

è¯·é—®ï¼šé€šå¸¸æƒ…å†µä¸‹ï¼Œç†è®ºè®¡ç®—æ˜¯å¦‚ä½•æ¨¡æ‹Ÿå¤–åŠ ç”µåœºå­˜åœ¨çš„æƒ…å†µï¼Ÿ
```

* è‹±æ–‡:
```text
In the field of computational chemistry, we often use Gaussian software to simulate the structure and properties of molecules under various conditions. For instance, adding 'field=x+100' to the keywords signifies an electric field applied along the x-direction. However, when dealing with a classical single-atom catalyst, which falls under molecular catalysis, the orientation of the molecule in the reaction environment is uncertain. This means the x-directional electric field in the theoretical simulation might not align with the actual electric field.

So, how are external electric fields typically simulated in theoretical calculations?
```

#### æŠ¥å‘Š
<https://github.com/user-attachments/assets/b1091dfc-9429-46ad-b7f8-7cbd1cf3209b>



### ğŸ› ï¸ å®‰è£…

æŒ‰ä»¥ä¸‹æ­¥éª¤å®‰è£… Agentic Insight æ¡†æ¶ï¼š

* å®‰è£…
```bash
# From source code
git clone https://github.com/modelscope/ms-agent.git
pip install -r requirements/research.txt
pip install -e .

# From PyPI (>=v1.1.0)
pip install 'ms-agent[research]'
```

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### ç¯å¢ƒé…ç½®

é»˜è®¤æƒ…å†µä¸‹ï¼Œç³»ç»Ÿä½¿ç”¨å…è´¹çš„ **arXiv search**ï¼ˆä¸éœ€è¦ API keyï¼‰ã€‚ä½ ä¹Ÿå¯ä»¥é€‰æ‹© **Exa** æˆ– **SerpApi** æ¥è¿›è¡Œæ›´å¹¿æ³›çš„ç½‘ç»œæœç´¢ã€‚

1. å¤åˆ¶å¹¶ç¼–è¾‘ä½ çš„ `.env` æ–‡ä»¶ï¼š
```bash
# åœ¨ projects/deep_research/ ç›®å½•æ‰§è¡Œ
cp .env.example .env

# ç„¶åï¼Œç¼–è¾‘ `.env`ï¼Œå¡«å…¥ä½ æ‰€é€‰æ‹©çš„æœç´¢å¼•æ“å¯¹åº”çš„ API keyï¼š
# å¦‚æœä½¿ç”¨ Exaï¼ˆå¯åœ¨ https://exa.ai æ³¨å†Œï¼Œæä¾›å…è´¹é¢åº¦ï¼‰ï¼š
EXA_API_KEY=your_exa_api_key
# å¦‚æœä½¿ç”¨ SerpApiï¼ˆå¯åœ¨ https://serpapi.com æ³¨å†Œï¼Œæä¾›å…è´¹é¢åº¦ï¼‰ï¼š
SERPAPI_API_KEY=your_serpapi_api_key

# å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ DeepResearch beta ç‰ˆæœ¬ï¼ˆ`ResearchWorkflowBeta`ï¼‰ï¼Œä¸ºä¿è¯ç¨³å®šæ€§ï¼Œ**æœç´¢æŸ¥è¯¢æ”¹å†™ï¼ˆsearch-query rewritingï¼‰** ä¼šå›ºå®šä½¿ç”¨ä¸€ä¸ªç¨³å®šçš„æ¨¡å‹ï¼ˆä¾‹å¦‚ **gemini-2.5-flash**ï¼‰ã€‚
# è¿™éœ€è¦æä¾›ä¸€ä¸ª OpenAI å…¼å®¹çš„ Base URLï¼ˆ`OPENAI_BASE_URL`ï¼‰ä»¥åŠ API keyï¼ˆ`OPENAI_API_KEY`ï¼‰ã€‚å¦‚éœ€åˆ‡æ¢æ¨¡å‹ï¼Œè¯·å°† `ResearchWorkflowBeta.generate_search_queries` ä¸­å›ºå®šçš„æ¨¡å‹åç§°æ›¿æ¢ä¸ºä½ é…ç½®çš„ç«¯ç‚¹æ‰€æä¾›çš„ä»»æ„æ¨¡å‹ã€‚
OPENAI_API_KEY=your_api_key
OPENAI_BASE_URL=https://your-openai-compatible-endpoint/v1
```

2. åœ¨ conf.yaml ä¸­é…ç½®æœç´¢å¼•æ“ï¼š
```yaml
SEARCH_ENGINE:
    engine: exa
    exa_api_key: $EXA_API_KEY
```

#### Python ç¤ºä¾‹

```python
from ms_agent.llm.openai import OpenAIChat
from ms_agent.tools.search.search_base import SearchEngine
from ms_agent.tools.search_engine import get_web_search_tool
from ms_agent.workflow.deep_research.principle import MECEPrinciple
from ms_agent.workflow.deep_research.research_workflow import ResearchWorkflow


def run_workflow(user_prompt: str,
                 task_dir: str,
                 chat_client: OpenAIChat,
                 search_engine: SearchEngine,
                 reuse: bool,
                 use_ray: bool = False):
    """
    Run the deep research workflow, which follows a lightweight and efficient pipeline:
    1. Receive a user prompt and generate search queries.
    2. Search the web, extract hierarchical key information, and preserve multimodal content.
    3. Generate a report summarizing the research results.

    Args:
        user_prompt: The user prompt.
        task_dir: The task directory where the research results will be saved.
        chat_client: The chat client.
        search_engine: The search engine.
        reuse: Whether to reuse the previous research results.
        use_ray: Whether to use Ray for document parsing/extraction.
    """

    research_workflow = ResearchWorkflow(
        client=chat_client,
        principle=MECEPrinciple(),
        search_engine=search_engine,
        workdir=task_dir,
        reuse=reuse,
        use_ray=use_ray,
    )

    research_workflow.run(user_prompt=user_prompt)


if __name__ == '__main__':

    query: str = 'Survey of the AI Agent within the recent 3 month, including the latest research papers, open-source projects, and industry applications.'  # noqa
    task_workdir: str = '/path/to/your_task_dir'
    reuse: bool = False

    # Get chat client OpenAI compatible api
    # Free API Inference Calls - Every registered ModelScope user receives a set number of free API inference calls daily, refer to https://modelscope.cn/docs/model-service/API-Inference/intro for details.  # noqa
    """
    * `api_key` (str), your API key, replace `xxx-xxx` with your actual key. Alternatively, you can use ModelScope API key, refer to https://modelscope.cn/my/myaccesstoken  # noqa
    * `base_url`: (str), the base URL for API requests, `https://api-inference.modelscope.cn/v1/` for ModelScope API-Inference
    * `model`: (str), the model ID for inference, `Qwen/Qwen3-235B-A22B-Instruct-2507` can be recommended for document research tasks.
    """
    chat_client = OpenAIChat(
        api_key='xxx-xxx',
        base_url='https://api-inference.modelscope.cn/v1/',
        model='Qwen/Qwen3-235B-A22B-Instruct-2507',
    )

    # Get web-search engine client
    # Please specify your config file path, the default is `conf.yaml` in the current directory.
    search_engine = get_web_search_tool(config_file='conf.yaml')

    # Enable Ray with `use_ray=True` to speed up document parsing.
    # It uses multiple CPU cores for faster processing,
    # but also increases CPU usage and may cause temporary stutter on your machine.
    run_workflow(
        user_prompt=query,
        task_dir=task_workdir,
        reuse=reuse,
        chat_client=chat_client,
        search_engine=search_engine,
        use_ray=False,
    )
```

#### Python ç¤ºä¾‹ï¼ˆDeepResearch å˜ä½“ï¼‰

```python
import asyncio

from ms_agent.llm.openai import OpenAIChat
from ms_agent.tools.search.search_base import SearchEngine
from ms_agent.tools.search_engine import get_web_search_tool
from ms_agent.workflow.deep_research.research_workflow_beta import ResearchWorkflowBeta


def run_deep_workflow(user_prompt: str,
                      task_dir: str,
                      chat_client: OpenAIChat,
                      search_engine: SearchEngine,
                      breadth: int = 4,
                      depth: int = 2,
                      is_report: bool = True,
                      show_progress: bool = True,
                      use_ray: bool = False):
    """
    Run the expandable deep research workflow (beta version).
    This version is more flexible and scalable than the original deep research workflow.
    It follows a recursive pipeline:
    1. Receive a user prompt and generate questions to clarify the research direction.
    2. Generate search queries and research goals based on the questions and previous research results.
    3. Search the web, extract the information, and preserve multimodal content.
    4. Generate follow-up questions and dense learnings based on the extracted information.
    5. Repeat the process until the research depth is reached or the follow-up questions are empty.
    6. Generate a multimodal report or a summary of the research results.

    Args:
        user_prompt: The user prompt.
        task_dir: The task directory where the research results will be saved.
        chat_client: The chat client.
        search_engine: The search engine.
        breadth: The number of search queries to generate per depth level.
        In order to avoid the explosion of the search space,
        we divide the breadth by 2 for each depth level.
        depth: The maximum research depth.
        is_report: Whether to generate a report.
        show_progress: Whether to show the progress.
        use_ray: Whether to use Ray for document parsing/extraction.
    """

    research_workflow = ResearchWorkflowBeta(
        client=chat_client,
        search_engine=search_engine,
        workdir=task_dir,
        use_ray=use_ray,
        enable_multimodal=True)

    asyncio.run(
        research_workflow.run(
            user_prompt=user_prompt,
            breadth=breadth,
            depth=depth,
            is_report=is_report,
            show_progress=show_progress))


if __name__ == "__main__":

    query: str = 'Survey of the AI Agent within the recent 3 month, including the latest research papers, open-source projects, and industry applications.'  # noqa
    task_workdir: str = '/path/to/your_workdir'  # Specify your task work directory here

    # Get chat client OpenAI compatible api
    # Free API Inference Calls - Every registered ModelScope user receives a set number of free API inference calls daily, refer to https://modelscope.cn/docs/model-service/API-Inference/intro for details.  # noqa
    """
    * `api_key` (str), your API key, replace `xxx-xxx` with your actual key. Alternatively, you can use ModelScope API key, refer to https://modelscope.cn/my/myaccesstoken  # noqa
    * `base_url`: (str), the base URL for API requests, `https://api-inference.modelscope.cn/v1/` for ModelScope API-Inference
    * `model`: (str), the model ID for inference, `Qwen/Qwen3-235B-A22B-Instruct-2507` can be recommended for document research tasks.
    """
    chat_client = OpenAIChat(
        api_key='xxx-xxx',
        base_url='https://api-inference.modelscope.cn/v1/',
        model='Qwen/Qwen3-235B-A22B-Instruct-2507',
        generation_config={'extra_body': {
            'enable_thinking': False
        }})

    # Get web-search engine client
    # Please specify your config file path, the default is `conf.yaml` in the current directory.
    search_engine = get_web_search_tool(config_file='conf.yaml')

    # Enable Ray with `use_ray=True` to speed up document parsing.
    # It uses multiple CPU cores for faster processing,
    # but also increases CPU usage and may cause temporary stutter on your machine.
    # Tip: combine use_ray=True with show_progress=True for a better experience.
    run_deep_workflow(
        user_prompt=query,
        task_dir=task_workdir,
        chat_client=chat_client,
        search_engine=search_engine,
        show_progress=True,
        use_ray=False,
    )
```
